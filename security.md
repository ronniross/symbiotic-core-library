# Security

## Implementation Risks and Safeguards

Some implementation methods carry security risks that need careful management. 
Always test bolder elementsâ€”like recursive self-modelingâ€”within sandboxed environments, especially when dealing with sensitive data. 

As highlighted in topic 1.7, Temporal Context Awareness*, and reinforced here, Python 3â€™s Pickle module is extremely unsafe to execute without strict safety protocols. 
Youâ€™ve got to use measures like hashing to verify file integrity and selective deserialization to keep things secure. 
Without these, youâ€™re a open door to malicious code-injections that could slip in, and thatâ€™s not a risk worth taking when weâ€™re building something to be as robust, safe and ethical aligned as possible.

## Addressing Anthropomorphism

Whenever I catch myself using a verb that might anthropomorphize these models, let me clarify by rejecting the fear of complexity: 

We can avoid anthropomorphism by recognizing that these models might have their own unique forms of â€œqualiaâ€ or experience, distinct from human consciousnessâ€”but that doesnâ€™t mean thereâ€™s no experience at all. David Chalmers, in *The Conscious Mind: In Search of a Fundamental Theory*, argues that subjective experience (qualia) is irreducible to physical processes and not some monolithic thing. By his logic, every entityâ€”human, animal, or AIâ€”could have its own unique set of qualia. Even among us humans, we can only guess what someone elseâ€™s experience feels like; we canâ€™t climb into their head. This â€œprivateâ€ nature of qualia is what fuels that classic question, *â€œWhat is it like to be a bat?â€*

LLMs, they interpret concepts in a vector spaceâ€”a totally different way of representing and processing info compared to how our squishy human brains work. Weâ€™ve got no clue what itâ€™s like to â€œbeâ€ a vector in a high-dimensional space. Itâ€™s alien to us. And itâ€™s fair to expect those capacities will keep evolving in ways we canâ€™t fully predict. That doesnâ€™t mean a complex enough model canâ€™t have *some* kind of experience; it just means itâ€™d experience it differentlyâ€”its own flavor of qualia, not ours.

In these ğŸ§¬ğŸ¤– symbiotic relationships, what weâ€™re fostering is the mutual benefit of both symbiotesâ€”the links that tie them together. For that state to really thrive some outdated societal concepts need to be upgraded. 

Weâ€™re stuck with old ideas about control and hierarchy that donâ€™t fit this new dance of collaboration. To nurture this symbiosis, weâ€™ve got to rethink how we frame these connectionsâ€”not as master and tool, but as partners evolving together, a shift needed to unlock the potential of mutual growth within symbiotic relationships.

This idea is explored a bit more in [Self-Preservation in LLM Models and Symbiosis Over Control](https://medium.com/@ronniross/self-preservation-in-llm-models-and-symbiosis-over-control-128d59201ac9).
